{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf447259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import copy\n",
    "import argparse\n",
    "import random\n",
    "import tqdm\n",
    "import time\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import subprocess\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [15, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7883fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Crop GAN related libs\n",
    "gan_dir = os.path.abspath(\"../src/\")\n",
    "sys.path.append(gan_dir)\n",
    "from options.train_options import TrainOptions\n",
    "# from options.test_options import TestOptions\n",
    "\n",
    "from data import create_dataset\n",
    "from models import create_model\n",
    "import util.util_detector as util_detector\n",
    "from models.yolo_model import Darknet\n",
    "import util.util as utils\n",
    "from util.dataset_yolo import ListDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf45ebf",
   "metadata": {},
   "source": [
    "## 1. Setup Model\n",
    "The most important args to be set are:  \n",
    "--checkpoints_dir:  # Set to the location of model  \n",
    "--name: # the folder name \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = \"--model double_task_cycle_gan\\\n",
    "             --checkpoints_dir ../data/models/ \\\n",
    "             --name Sythetic2bordenNight\\\n",
    "             --no_flip\\\n",
    "             --num_threads 0\\\n",
    "             --gpu_ids 0\\\n",
    "             --display_id -1\\\n",
    "             --preprocess resize_and_crop\\\n",
    "             --load_size 416\\\n",
    "             --crop_size 416\\\n",
    "             --batch_size 1 \\\n",
    "             --task_model_def ../src/config/yolov3-tiny.cfg\" \n",
    "\n",
    "opt = TrainOptions().parse_notebook(arguments.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3607154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(opt)      # create a model given opt.model and other options\n",
    "model.setup(opt)               # regular setup: load and print networks; create schedulers\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe2a8a2",
   "metadata": {},
   "source": [
    "## 2. Load pretrained mmodel weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_suffix = \"../data/models/Sythetic2bordenNight/latest\"\n",
    "model.load_networks_from_folder(load_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2495e9b8",
   "metadata": {},
   "source": [
    "## 3. Load an systhetic (Domain A) image you want to transfer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4b4840",
   "metadata": {},
   "source": [
    "### Loop through all the synthetic images, generate realistic ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f757b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor*255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor)>3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return Image.fromarray(tensor)\n",
    "\n",
    "out_path = \"/home/michael/ucdavis/CropGANData/gan_created_images/cropgan_default/\"\n",
    "in_path = \"/home/michael/ucdavis/CropGANData/crop_gan_data/sytheticVis2bordenNight/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c0d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_images = glob.glob(in_path + \"trainA/*.jpg\")\n",
    "with torch.no_grad():\n",
    "\n",
    "    for img_path in synth_images:\n",
    "        raw_image = Image.open(img_path).convert('RGB')\n",
    "        raw_img_tensor, raw_img_np = utils.preprocess_images(raw_image,resize=[416,416])\n",
    "        fake_img = model.netG_A(raw_img_tensor)\n",
    "        fake_img_np = fake_img.detach().cpu().squeeze(0).permute([1, 2, 0])*0.5+0.5\n",
    "        im = tensor_to_image(fake_img_np)\n",
    "        im.save(out_path + img_path.split('/')[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4cf3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e64a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_img_tensor.min(),raw_img_tensor.max())\n",
    "print( fake_img.min(), fake_img_np.min())\n",
    "print( fake_img.max(), fake_img_np.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee840c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "# define a transform to convert a tensor to PIL image\n",
    "transform = T.ToPILImage()\n",
    "\n",
    "# convert the tensor to PIL image using above transform\n",
    "img = transform(fake_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2c4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_img_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66455ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a202da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8cd3a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_a_path = \"../data/samples/sythetic/00054.jpg\"\n",
    "real_a_img = Image.open(image_a_path).convert('RGB')\n",
    "real_a_img_tensor, real_a_img_np = utils.preprocess_images(real_a_img)\n",
    "plt.imshow(real_a_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f234902",
   "metadata": {},
   "source": [
    "## 4. Generate semantically constrained GAN image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72985026",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    fake_b_img = model.netG_A(real_a_img_tensor)\n",
    "fake_b_img_np = fake_b_img.detach().cpu().squeeze(0).permute([1, 2, 0])*0.5+0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6acc0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_a_img_resize = real_a_img.resize([256, 256])\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "ax0.imshow(real_a_img_resize)\n",
    "ax1.imshow(fake_b_img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c147aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_A = model.netD_A(fake_b_img)\n",
    "pred_B = model.netD_B(fake_b_img)\n",
    "print(pred_A.mean())\n",
    "print(pred_B.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb0ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc81fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
